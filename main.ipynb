{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPom/venzPrIf2UzQLPvBbd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatteoOnger/algo-collusion-mm/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Algorithmic Collusion in Market Making"
      ],
      "metadata": {
        "id": "EMTOP3utEbcK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A notebook testing various (RL) agents implementing market-making strategies in the Glosten-Milgrom environment."
      ],
      "metadata": {
        "id": "CGZMs7D1J3fF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notebook Initialization"
      ],
      "metadata": {
        "id": "FxmHCO7rFONX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Colab Environment Setup"
      ],
      "metadata": {
        "id": "DResD4xyGhBX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOP-nvvbEYvD",
        "outputId": "8fd4915f-976a-44e7-cf63-5510118e4d6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'algo-collusion-mm'...\n",
            "remote: Enumerating objects: 391, done.\u001b[K\n",
            "remote: Counting objects: 100% (108/108), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 391 (delta 44), reused 82 (delta 22), pack-reused 283 (from 1)\u001b[K\n",
            "Receiving objects: 100% (391/391), 81.00 KiB | 1.09 MiB/s, done.\n",
            "Resolving deltas: 100% (172/172), done.\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.7/515.7 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m852.5/852.5 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h/content/algo-collusion-mm\n"
          ]
        }
      ],
      "source": [
        "# Do NOT run this cell in local environment - it's intended for Google Colab only.\n",
        "\n",
        "# Clone GitHub repository\n",
        "!git clone https://github.com/MatteoOnger/algo-collusion-mm.git\n",
        "\n",
        "# Install dependencies\n",
        "!pip install --quiet -r /content/algo-collusion-mm/requirements.txt\n",
        "\n",
        "# Set working directory\n",
        "%cd /content/algo-collusion-mm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Local Environment Setup"
      ],
      "metadata": {
        "id": "udKsn5GQHHt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Do NOT run this cell in Google Colab - it's intended for local Jupyter Notebooks only.\n",
        "\n",
        "# Autoreload imports\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# Select interactive backend for matplotlib\n",
        "%matplotlib widget"
      ],
      "metadata": {
        "id": "XOKNp7tDFKHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Execution"
      ],
      "metadata": {
        "id": "_1Ulv9GBHZaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import src.utils.plots as plots\n",
        "import src.utils.storage as storage\n",
        "\n",
        "from src.agents.agent import Agent\n",
        "from src.agents.makers.exp3 import MakerEXP3\n",
        "from src.agents.makers.mlql import MakerMLQL, MakerInformedMLQL\n",
        "from src.agents.makers.ql import MakerInformedQL\n",
        "from src.agents.traders.basic import BasicTrader\n",
        "from src.agents.traders.nopass import NoPassTrader\n",
        "from src.envs import GMEnv"
      ],
      "metadata": {
        "id": "gxDHqYnXrDzE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_array(arr: np.ndarray, window_size: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Split an array into sub-arrays of fixed window size along the last axis.\n",
        "\n",
        "    If `window_size` is non-positive, the array is reshaped so that the last\n",
        "    axis becomes a single window of length equal to its size.\n",
        "    This is useful, for example, to ensure a consistent 3D shape\n",
        "    when no actual splitting is performed.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    arr : np.ndarray\n",
        "        Input array to be split.\n",
        "    window_size : int\n",
        "        Size of each window. Must be a positive integer.\n",
        "        If <= 0, the array is reshaped to (..., 1, N), where N is the\n",
        "        original length of the last axis.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    : np.ndarray\n",
        "        Reshaped array with shape (..., n_windows, window_size).\n",
        "        If `window_size <= 0`, returns the original array.\n",
        "\n",
        "    Raises\n",
        "    ------\n",
        "    ValueError\n",
        "        If `window_size` is not a divisor of the length of the last axis.\n",
        "    \"\"\"\n",
        "    if window_size <= 0:\n",
        "        return arr.reshape(arr.shape[:-1] + (1, -1))\n",
        "    return arr.reshape(arr.shape[:-1] + (-1, window_size))\n",
        "\n",
        "\n",
        "def get_calvano_collusion_index(rewards: np.ndarray, nash_reward: float, coll_reward: float, window_size: int = 0) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Compute the Calvano Collusion Index (CCI) from agent rewards.\n",
        "\n",
        "    The CCI measures the degree of collusion relative to Nash equilibrium\n",
        "    and perfect collusion benchmarks. Rewards are optionally aggregated\n",
        "    over fixed-size windows before computing the index.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    rewards : np.ndarray\n",
        "        Array of shape (n_agents, n_episodes) containing per-agent rewards.\n",
        "    nash_reward : float\n",
        "        Benchmark reward under Nash equilibrium (total across all agents).\n",
        "    coll_reward : float\n",
        "        Benchmark reward under perfect collusion (total across all agents).\n",
        "    window_size : int, default=0\n",
        "        Size of the episode window for reward aggregation.\n",
        "        If 0, no windowing is applied.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    : np.ndarray\n",
        "        Array of CCI values per agent and per window.\n",
        "\n",
        "    See Also\n",
        "    --------\n",
        "    - Calvano, E., Calzolari, G., Denicolò, V., & Pastorello, S. (2020).\n",
        "    Artificial intelligence, algorithmic pricing, and collusion.\n",
        "    *American Economic Review, 110*(10), 3267–3297.\n",
        "    https://doi.org/10.1257/aer.20190623\n",
        "    \"\"\"\n",
        "    nash_reward /= len(rewards)\n",
        "    coll_reward /= len(rewards)\n",
        "\n",
        "    rewards = split_array(rewards, window_size)\n",
        "    avg_rewards = rewards.mean(axis=-1)\n",
        "\n",
        "    cci = (avg_rewards - nash_reward) / (coll_reward - nash_reward)\n",
        "    return cci"
      ],
      "metadata": {
        "id": "j3GakIjfrFfE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saver = storage.ExperimentStorage('./experiments')"
      ],
      "metadata": {
        "id": "rnadvQcZrI2c"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 50_000          # Number of episodes\n",
        "w = n // 1000       # Window size\n",
        "\n",
        "nash_reward = 0.1  # Nash reward\n",
        "coll_reward = 0.5  # Collusive reward\n",
        "\n",
        "action_space = np.array([[0.0, 0.0], [0.6, 0.4], [0.8, 0.2], [1.0, 0.0]])\n",
        "\n",
        "for i in range(10):\n",
        "    if i % 10 == 0:\n",
        "        print(f'Running {i} ...')\n",
        "\n",
        "    agents: dict[str, Agent] = {\n",
        "        'maker_u_0': MakerEXP3(epsilon=MakerEXP3.compute_epsilon(len(action_space), n), action_space=action_space, name='maker_u_0'),\n",
        "        'maker_u_1': MakerEXP3(epsilon=MakerEXP3.compute_epsilon(len(action_space), n), action_space=action_space, name='maker_u_1'),\n",
        "        'trader_0': NoPassTrader(name='trader_0'),\n",
        "    }\n",
        "\n",
        "    env = GMEnv(\n",
        "        generate_vt = lambda: 0.5,\n",
        "        n_episodes = n,\n",
        "        n_makers_u = 2,\n",
        "        n_makers_i = 0,\n",
        "        n_traders = 1,\n",
        "    )\n",
        "\n",
        "    _, info = env.reset()\n",
        "\n",
        "    for agent in env.agent_iter():\n",
        "\n",
        "        action = agents[agent].act(env.observe(agent))\n",
        "        _, rewards, _, _, infos = env.step(action)\n",
        "\n",
        "        if infos['episode_finished']:\n",
        "            for a in env.possible_agents:\n",
        "                agents[a].update(rewards[a], infos[a])\n",
        "\n",
        "\n",
        "    cci = get_calvano_collusion_index(\n",
        "        np.array([agent.history.get_rewards() for name, agent in agents.items() if name in env.makers]),\n",
        "        nash_reward = nash_reward,\n",
        "        coll_reward = coll_reward,\n",
        "        window_size = w\n",
        "    )\n",
        "\n",
        "    info = {\n",
        "        'parmas' : {\n",
        "            'n_episodes' : n,\n",
        "            'window_size' : w,\n",
        "            'action_space' : str(action_space),\n",
        "            'agent_type' : [agent.__class__.__name__ for agent in agents.values()],\n",
        "        },\n",
        "        'most_common_action' : {\n",
        "            n//w : {name : str(agent.history.compute_most_common(slice(-w, None))) for name, agent in agents.items() if name in env.makers}\n",
        "        },\n",
        "        'cumulative_rewards' : {\n",
        "            0  : {name : round(float(agent.history.get_rewards(slice(0, w)).sum()), 3) for name, agent in agents.items()},\n",
        "            n//w : {name : round(float(agent.history.get_rewards(slice(-w, None)).sum()), 3) for name, agent in agents.items()},\n",
        "            'global' : env.cumulative_rewards\n",
        "        },\n",
        "        'cci' : {\n",
        "            0  : {name : round(float(cci[idx, 0]), 3) for idx, name in enumerate(env.makers)},\n",
        "            n//w  : {name : round(float(cci[idx, -1]), 3) for idx, name in enumerate(env.makers)},\n",
        "            'global' : {name : round(float(cci[idx, :].mean()), 3) for idx, name in enumerate(env.makers)},\n",
        "        },\n",
        "        'seed' : {\n",
        "            name : agent._seed for name, agent in agents.items()\n",
        "        }\n",
        "    }\n",
        "\n",
        "    dir = saver.save_objects([env] + list(agents.values()), info=info)\n",
        "\n",
        "    if info['cumulative_rewards'][n//w]['maker_u_0'] > 3.0 or info['cumulative_rewards'][n//w]['maker_u_1'] > 3.0:\n",
        "        print(f'{i} -> CCI:{info[\"cci\"][n//w]} CR:{info[\"cumulative_rewards\"][n//w]} ({dir})')\n",
        "\n",
        "print('Done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80Oq4lNWrKcl",
        "outputId": "bfb5ec16-d1d7-401a-d3db-61f41036ee09"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running 0 ...\n",
            "0 -> CCI:{'maker_u_0': 0.47, 'maker_u_1': 0.49} CR:{'maker_u_0': 7.2, 'maker_u_1': 7.4, 'trader_0': -14.6} (./experiments/experiment_017_20250930_150958)\n",
            "1 -> CCI:{'maker_u_0': 0.42, 'maker_u_1': 0.48} CR:{'maker_u_0': 6.7, 'maker_u_1': 7.3, 'trader_0': -14.0} (./experiments/experiment_018_20250930_151039)\n",
            "2 -> CCI:{'maker_u_0': 0.5, 'maker_u_1': 0.5} CR:{'maker_u_0': 7.5, 'maker_u_1': 7.5, 'trader_0': -15.0} (./experiments/experiment_019_20250930_151118)\n",
            "3 -> CCI:{'maker_u_0': 0.5, 'maker_u_1': 0.5} CR:{'maker_u_0': 7.5, 'maker_u_1': 7.5, 'trader_0': -15.0} (./experiments/experiment_020_20250930_151158)\n",
            "4 -> CCI:{'maker_u_0': 0.5, 'maker_u_1': 0.5} CR:{'maker_u_0': 7.5, 'maker_u_1': 7.5, 'trader_0': -15.0} (./experiments/experiment_021_20250930_151239)\n",
            "5 -> CCI:{'maker_u_0': 0.5, 'maker_u_1': 0.5} CR:{'maker_u_0': 7.5, 'maker_u_1': 7.5, 'trader_0': -15.0} (./experiments/experiment_022_20250930_151320)\n",
            "6 -> CCI:{'maker_u_0': 0.42, 'maker_u_1': 0.48} CR:{'maker_u_0': 6.7, 'maker_u_1': 7.3, 'trader_0': -14.0} (./experiments/experiment_023_20250930_151400)\n",
            "7 -> CCI:{'maker_u_0': 0.515, 'maker_u_1': 0.405} CR:{'maker_u_0': 7.65, 'maker_u_1': 6.55, 'trader_0': -14.2} (./experiments/experiment_024_20250930_151440)\n",
            "8 -> CCI:{'maker_u_0': 0.485, 'maker_u_1': 0.435} CR:{'maker_u_0': 7.35, 'maker_u_1': 6.85, 'trader_0': -14.2} (./experiments/experiment_025_20250930_151522)\n",
            "9 -> CCI:{'maker_u_0': 0.485, 'maker_u_1': 0.515} CR:{'maker_u_0': 7.35, 'maker_u_1': 7.65, 'trader_0': -15.0} (./experiments/experiment_026_20250930_151603)\n",
            "Done\n"
          ]
        }
      ]
    }
  ]
}